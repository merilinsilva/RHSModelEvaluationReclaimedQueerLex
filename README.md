# RHSModelEvaluationReclaimedQueerLex

This contains the ReclaimedQueerLex dataset by Rebecca Dorn et al. [1] and a Python script, which preprocesses the dataset and evaluates it using a hate speech detection model, fine-tuned on LGBTQ+ reclaimed language called the RHS model [2].

In the end the code for a LateX table is outputed with the Precision, Recall and F1-Score of hate and non-hate labels, given by Detoxify, Perspective and the RHS model.

## Sources:
[1] Rebecca Dorn, et al. (2024). Harmful Speech Detection by Language Models Exhibits Gender-Queer Dialect Bias. _In Proceedings of the 4th ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization (EAAMO '24)_. Association for Computing Machinery, New York, NY, USA, 1–12. doi.org/10.1145/3689904.3694704. 

[2] Eszter Zsisku, et al. (2024). Hate Speech Detection and Reclaimed Language: Mitigating False Positives and Compounded Discrimination. _In Proceedings of the 16th ACM Web Science Conference_, 241–249, doi.org/10.1145/3614419.3644025.
